{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b5adfb5-0c76-4206-9594-271eef45bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1c933f28-b278-4b62-a6b8-0f40bb6bba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, head_dim, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_in = d_in\n",
    "        self.d_out = head_dim*num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = head_dim\n",
    "        self.W_query = nn.Linear(d_in, self.d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, self.d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, self.d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out_proj = nn.Linear(self.d_out, self.d_out)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "        \n",
    "    def forward(self, input_layer):\n",
    "        batch, sequence_len, input_dim = input_layer.shape\n",
    "        queries = self.W_query(input_layer)\n",
    "        keys = self.W_key(input_layer)\n",
    "        values = self.W_value(input_layer)\n",
    "        # q , k , v shapes are like this - [batch, seq_len, d_out]\n",
    "        # reshape them to be - [batch, seq_len, head, head_dim]\n",
    "        queries = queries.view(batch, sequence_len, self.num_heads, self.head_dim)\n",
    "        keys = keys.view(batch, sequence_len, self.num_heads, self.head_dim)\n",
    "        values = values.view(batch, sequence_len, self.num_heads, self.head_dim)\n",
    "        queries = queries.transpose(1,2)\n",
    "        keys = keys.transpose(1,2)\n",
    "        values = values.transpose(1,2)\n",
    "        # q, k , v shape - [batch, head, seq_len, head_dim]\n",
    "        attn_scores = queries @ keys.transpose(2,3)\n",
    "        # attn_scores shape - [batch, head, seq_len, seq_len]\n",
    "        attn_scores = attn_scores.masked_fill(self.mask.bool()[:sequence_len, :sequence_len], -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores/math.sqrt(self.head_dim), dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        context_vec = attn_weights @ values\n",
    "        # context_vec shape - [batch, num_heads, seq_len, head_dim]\n",
    "        context_vec = context_vec.transpose(1,2).contiguous().view(batch, sequence_len, self.d_out)\n",
    "        out_proj = self.out_proj(context_vec)\n",
    "        return out_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b246980e-99dc-4dbf-b6d3-052347f28b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 2\n",
    "seq_len = 3\n",
    "d_in = 5\n",
    "head_dim = 5\n",
    "context_len = 5\n",
    "dropout = 0.1\n",
    "num_heads = 2\n",
    "# d_out will be 400*5 = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d163de79-873f-4835-9aeb-2d73b1a693f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = MultiHeadAttention(d_in, head_dim, context_len, dropout, num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1f159e03-6d90-4a31-b5f1-f34a6e57be04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 260\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in mha.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3e5946c1-d06e-410e-aba0-0946bcc3e09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(batch, seq_len, d_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2cdc116d-be70-48c1-a122-cc8b7f39604e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = mha(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e9bbc1f5-52c3-42e7-8e67-7e4ac93c3bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 10])\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e7a22eaa-f469-41a5-8684-861d51392616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1363, -0.0252,  0.3123, -0.2153, -0.2828, -0.1511,  0.3966,\n",
      "           0.0476,  0.5206,  0.5171],\n",
      "         [ 0.1866, -0.0819,  0.3330, -0.1300, -0.2103, -0.1940,  0.3484,\n",
      "           0.0607,  0.5241,  0.4756],\n",
      "         [ 0.3216, -0.0443,  0.0479, -0.3863, -0.3033, -0.1601,  0.1961,\n",
      "          -0.1051,  0.2081,  0.4516]],\n",
      "\n",
      "        [[ 0.1345, -0.3399,  0.3063,  0.2915,  0.2007,  0.3696, -0.5283,\n",
      "           0.0192,  0.5290, -0.1796],\n",
      "         [ 0.0671, -0.3187, -0.1127,  0.3623,  0.0985,  0.4154, -0.7602,\n",
      "           0.0150,  0.3262, -0.2289],\n",
      "         [ 0.1386, -0.3822, -0.0712,  0.2497,  0.0062,  0.3670, -0.5348,\n",
      "          -0.1006,  0.4150, -0.0215]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f494ab8b-5abc-46c7-9cdf-7a5a43d0de49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False,  True,  True,  True,  True],\n",
      "        [False, False,  True,  True,  True],\n",
      "        [False, False, False,  True,  True],\n",
      "        [False, False, False, False,  True],\n",
      "        [False, False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(context_len, context_len), diagonal=1)\n",
    "mask = mask.bool()\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "01019c51-73f7-4240-9f60-da3f8f0347e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_in, dropout):\n",
    "        super().__init__()\n",
    "        self.activation = nn.GELU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer1 = nn.Linear(d_in, 4*d_in)\n",
    "        self.layer2 = nn.Linear(4*d_in, d_in)\n",
    "    def forward(self, input_tensor):\n",
    "        x = self.layer1(input_tensor)\n",
    "        x = self.activation(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7f345c5b-04ee-4bae-a2b9-aa0d519cf34c",
   "metadata": {},
   "outputs": [],
   "source": [
    " class LayerNorm(nn.Module):          \n",
    "    def __init__(self, emb_dim):   \n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "                                  \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x-mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "228368c2-b941-44a5-bb7f-97b5e4ae9208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1., 1., 1., 1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Parameter(torch.ones(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d31e5a18-5142-446f-b7c9-64a8a69f1fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = FeedForward(GPT_CONFIG_124M[\"emb_dim\"], GPT_CONFIG_124M[\"dropout\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "73457232-b589-4189-842e-5ac8136bafd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 4,722,432\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in ff.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "afa2c4db-70e7-4c04-97b2-ffece127a322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1552, -0.0985,  0.0164,  0.0320,  0.0066],\n",
       "         [ 0.1247, -0.0298,  0.0656, -0.0014,  0.1116],\n",
       "         [ 0.2474,  0.1433, -0.0559, -0.2302,  0.0719]],\n",
       "\n",
       "        [[ 0.2712, -0.4586, -0.0041,  0.0925,  0.0307],\n",
       "         [ 0.0747,  0.1404,  0.0000, -0.0840,  0.0527],\n",
       "         [ 0.0000, -0.2969,  0.1940, -0.1839,  0.2872]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8f218296-2c8c-4908-8d34-1f35e5e6151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.layer_norm1 = LayerNorm(config[\"emb_dim\"])\n",
    "        assert(config[\"head_dim\"] * config[\"num_heads\"] == config[\"emb_dim\"])\n",
    "        self.attention_block = MultiHeadAttention(config[\"emb_dim\"], config[\"head_dim\"], config[\"context_len\"], config[\"dropout\"], \n",
    "                                                  config[\"num_heads\"], config[\"qkv_bias\"])\n",
    "        self.dropout = nn.Dropout(config[\"dropout\"])\n",
    "        self.layer_norm2 = LayerNorm(config[\"emb_dim\"])\n",
    "        self.ff = FeedForward(config[\"emb_dim\"], config[\"dropout\"])\n",
    "    def forward(self, input_tensor):\n",
    "        x = self.layer_norm1(input_tensor)\n",
    "        x = self.attention_block(x)\n",
    "        x = self.dropout(x)\n",
    "        second_input = x + input_tensor\n",
    "        x = self.layer_norm2(second_input)\n",
    "        x = self.ff(x)\n",
    "        out = x+second_input\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e23f097a-c173-4707-85ca-3df86ab5f3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "\"vocab_size\": 50257,     # Vocabulary size\n",
    "\"context_len\": 256,  # Context length\n",
    "\"head_dim\" : 64,\n",
    "\"emb_dim\": 768,          # Embedding dimension\n",
    "\"num_heads\": 12,           # Number of attnention heads\n",
    "\"n_layers\": 12,          # Number of layers\n",
    "\"dropout\": 0.1,        # Dropout rate\n",
    "\"qkv_bias\": False        # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "31d60b63-14b1-4154-b697-068d40d34b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 4, 768)                  \n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fb8970ff-9051-4b94-9193-d32c0e22b8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(config[\"vocab_size\"], config[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(config[\"context_len\"], config[\"emb_dim\"])\n",
    "        self.dropout = nn.Dropout(config[\"dropout\"])\n",
    "        self.trf_blocks = nn.Sequential(*[TransformerBlock(config) for _ in range(config[\"n_layers\"])])\n",
    "        self.final_layer_norm = LayerNorm(config[\"emb_dim\"])\n",
    "        self.output_layer = nn.Linear(config[\"emb_dim\"], config[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        batch, seq_len = input_tensor.shape\n",
    "        tok_emb = self.tok_emb(input_tensor)\n",
    "        pos_emb = self.pos_emb(torch.arange(seq_len, device = input_tensor.device))\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.dropout(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_layer_norm(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "50db8e9e-8482-4299-8a97-67aa9308cb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b8c6cb0b-b31f-486d-af46-41f261d08dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 8.6199e-03,  6.3280e-01,  2.1399e-01,  ...,  5.7252e-01,\n",
      "          -1.6893e-01, -5.4216e-01],\n",
      "         [ 1.1306e+00, -7.9799e-01, -1.1022e-01,  ...,  5.9146e-01,\n",
      "           1.9603e-01, -2.3746e-01],\n",
      "         [ 2.0163e-02,  3.6033e-02, -4.0366e-01,  ..., -1.1639e-03,\n",
      "           3.4936e-01,  4.5264e-01],\n",
      "         [ 4.1024e-01, -2.6074e-01,  3.2827e-01,  ...,  1.2635e+00,\n",
      "           4.6138e-02,  9.8668e-01]],\n",
      "\n",
      "        [[ 5.8559e-01,  3.7186e-01, -1.2099e-01,  ...,  4.6907e-01,\n",
      "          -1.3180e+00, -4.7436e-01],\n",
      "         [ 6.6893e-01, -6.7278e-01, -3.6985e-01,  ..., -1.6321e-01,\n",
      "          -4.4507e-01, -2.2840e-01],\n",
      "         [ 1.9243e-01,  1.0521e+00, -1.3014e-01,  ..., -2.0987e-01,\n",
      "          -7.8911e-02,  1.2126e-01],\n",
      "         [ 4.4798e-01,  4.1775e-01,  4.9786e-01,  ...,  7.0224e-01,\n",
      "           5.1943e-01,  1.4487e-01]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "aa89399d-d399-4abf-88a4-c5981d800297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 162,419,712\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc717aa-e316-4687-b518-65f39cf8717b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
